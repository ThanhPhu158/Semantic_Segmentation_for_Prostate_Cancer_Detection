{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":403,"status":"ok","timestamp":1693298782633,"user":{"displayName":"Thái Bảo Nguyễn","userId":"10464131796033627061"},"user_tz":-420},"id":"s2AeI5dQoVgX","outputId":"c2ab30b0-a2e1-4f4b-d9f4-6a8a51f214d3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Tue Aug 29 08:46:21 2023       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla V100-SXM2...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    24W / 300W |      0MiB / 16384MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}],"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Not connected to a GPU')\n","else:\n","  print(gpu_info)"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17839,"status":"ok","timestamp":1693298800469,"user":{"displayName":"Thái Bảo Nguyễn","userId":"10464131796033627061"},"user_tz":-420},"id":"2jXQG40smnPN","outputId":"ab6e508e-03df-4477-a43f-af5c6fee3dd3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":3,"metadata":{"executionInfo":{"elapsed":7437,"status":"ok","timestamp":1693298807903,"user":{"displayName":"Thái Bảo Nguyễn","userId":"10464131796033627061"},"user_tz":-420},"id":"JVRxwVqumjbZ"},"outputs":[],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","import albumentations as A\n","from albumentations.pytorch import ToTensorV2 # np.array -> torch.tensor\n","import os\n","import os.path as osp\n","from PIL import Image\n","from torchvision import transforms as T\n","from tqdm import tqdm\n","from glob import glob\n","import datetime\n","import time"]},{"cell_type":"markdown","metadata":{"id":"mJAWW1e6mjbc"},"source":["## <center>Multi-scale Parallel Branch PsPnet and Fully Convolutional DenseNets</center>"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1693298807904,"user":{"displayName":"Thái Bảo Nguyễn","userId":"10464131796033627061"},"user_tz":-420},"id":"e_lLhxSCmjbd"},"outputs":[],"source":["class Layer(nn.Module):\n","    def __init__(self, in_ch, kernel_s=3, padding='same', dilation=1, stride=1, grow_rate=16, dropRate=0.2):\n","        super(Layer, self).__init__()\n","        self.relu = nn.ReLU(inplace=True)\n","        self.bn = nn.BatchNorm2d(in_ch)\n","        self.conv = nn.Conv2d(in_ch, grow_rate, kernel_size=kernel_s, stride=stride,\n","                               padding=padding, dilation=dilation, bias=False)\n","        self.droprate = nn.Dropout(p=dropRate)\n","    def forward(self, x):\n","        x_out = self.conv(self.relu(self.bn(x)))\n","        x_out = self.droprate(x_out)\n","        return x_out"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1693298807904,"user":{"displayName":"Thái Bảo Nguyễn","userId":"10464131796033627061"},"user_tz":-420},"id":"JGoY8BM7mjbe"},"outputs":[],"source":["class DenseBlock(nn.Module):\n","    def __init__(self, in_ch, kernel_s=3, padding='same', dilation=1, stride=1, grow_rate=16, n_layers=4, Upsample=False):\n","        super(DenseBlock, self).__init__()\n","        self.upsample = Upsample\n","        self.layers = nn.ModuleList([Layer(in_ch + i*grow_rate, kernel_s, padding, dilation, stride, grow_rate)\n","                                     for i in range(n_layers)])\n","        self.n_layers = n_layers\n","\n","    def forward(self, x):\n","        if self.upsample:\n","            new_features = []\n","            for layer in self.layers:\n","                x_out = layer(x)\n","                x = torch.cat([x, x_out], 1)\n","                new_features.append(x_out)\n","            return torch.cat(new_features,1)\n","        else:\n","            layer_arr = [x]\n","            for i in range(self.n_layers):\n","                x_out = self.layers[i](x)\n","                layer_arr.append(x_out)\n","                if i == self.n_layers - 1:\n","                    x = torch.cat(layer_arr, 1)\n","                else:\n","                    x = torch.cat([x, x_out], 1)\n","            return x\n"]},{"cell_type":"code","execution_count":6,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1693298807905,"user":{"displayName":"Thái Bảo Nguyễn","userId":"10464131796033627061"},"user_tz":-420},"id":"Z_bIdeeYmjbf"},"outputs":[],"source":["class TransitionDown(nn.Module):\n","    def __init__(self, in_ch, dropRate=0.15):\n","        super(TransitionDown, self).__init__()\n","        self.bn = nn.BatchNorm2d(in_ch)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv = nn.Conv2d(in_ch, in_ch, kernel_size=1, stride=1, padding='same', bias=False)\n","        self.pooling =  nn.MaxPool2d(kernel_size=2, stride=2)\n","        self.droprate = nn.Dropout(p=dropRate)\n","    def forward(self, x):\n","        x_out = self.conv(self.relu(self.bn(x)))\n","        x_out = self.droprate(x_out)\n","        x_out = self.pooling(x_out)\n","        return x_out"]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1693298807905,"user":{"displayName":"Thái Bảo Nguyễn","userId":"10464131796033627061"},"user_tz":-420},"id":"nAe4CpMFmjbf"},"outputs":[],"source":["def center_crop(layer, max_height, max_width):\n","    _, _, h, w = layer.size()\n","    xy1 = (w - max_width) // 2\n","    xy2 = (h - max_height) // 2\n","    return layer[:, :, xy2:(xy2 + max_height), xy1:(xy1 + max_width)]"]},{"cell_type":"code","execution_count":8,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1693298807905,"user":{"displayName":"Thái Bảo Nguyễn","userId":"10464131796033627061"},"user_tz":-420},"id":"PLwvfaJXmjbg"},"outputs":[],"source":["class TransitionUp(nn.Module):\n","    def __init__(self, in_ch, out_ch, kernel_s=3):\n","        super(TransitionUp, self).__init__()\n","        self.transpose = nn.ConvTranspose2d(in_ch, out_ch, kernel_size=kernel_s, stride=2, padding=0, bias=True)\n","    def forward(self, x, skip_connection):\n","        x_out = self.transpose(x)\n","        x_out = center_crop(x_out, skip_connection.size(2), skip_connection.size(3))\n","        x_out = torch.cat([x_out, skip_connection], 1)\n","        return x_out"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1693298807905,"user":{"displayName":"Thái Bảo Nguyễn","userId":"10464131796033627061"},"user_tz":-420},"id":"2hrJZgUqmjbg"},"outputs":[],"source":["class MPB_FCDenseNet(nn.Module):\n","    def __init__(self, in_ch=3, down_blocks=(4, 5, 6, 7, 8),\n","                 up_blocks=(8 , 7 , 6, 5 ,4), bottleneck_layers=10,\n","                 grow_rate=16, kernel_s=[3, 5, 9], padding='same', dilation=1, stride=1, m=48, n_classes=6):\n","        super(MPB_FCDenseNet, self).__init__()\n","        self.down_blocks = down_blocks\n","        self.up_blocks = up_blocks\n","        self.criterion = nn.CrossEntropyLoss(ignore_index=255)\n","        #   First Convolution   #\n","        #########################\n","        self.first_conv = nn.Conv2d(in_channels=in_ch, out_channels=m, kernel_size=3, stride=1, padding=1, bias=True)\n","        #########################################################################\n","        #############################   Multi Gate  #############################\n","        current_ch = m\n","        skip_ch = []\n","        #   Downsampling    #\n","        #####################\n","        self.DB_down_1 = nn.ModuleList([])\n","        self.TD_1 = nn.ModuleList([])\n","        for i in range(len(down_blocks)):\n","            if i == 0:\n","                dilation_d = 1\n","            elif i%2 == 0:\n","                dilation_d = 4\n","            else:\n","                dilation_d = 2\n","            self.DB_down_1.append(DenseBlock(current_ch, kernel_s[0], padding, dilation_d, stride, grow_rate, down_blocks[i], False))\n","            current_ch +=(down_blocks[i]*grow_rate)\n","            skip_ch.insert(0,current_ch)\n","            self.TD_1.append(TransitionDown(current_ch))\n","        #   bottleneck_1   #\n","        ##################\n","        # Layer : DB (15 layers), m = 896\n","        self.bottleneck = DenseBlock(current_ch, kernel_s[0], padding, 2, 1, grow_rate, bottleneck_layers, True)\n","        prev_ch = (bottleneck_layers*grow_rate)\n","        current_ch += prev_ch\n","        #   Upsampling path   #\n","        #######################\n","        self.DB_up_1 = nn.ModuleList([])\n","        self.TU_1 = nn.ModuleList([])\n","        for i in range(len(up_blocks)-1):\n","            kernel_tu = 3\n","            self.TU_1.append(TransitionUp(prev_ch, prev_ch, kernel_tu))\n","            current_ch = prev_ch + skip_ch[i]\n","            self.DB_up_1.append(DenseBlock(current_ch, kernel_s[0], padding, 2, 1, grow_rate, up_blocks[i], True))\n","            prev_ch = grow_rate*up_blocks[i]\n","            current_ch += prev_ch\n","        #   Final DenseBlock    #\n","        #########################\n","        self.TU_1.append(TransitionUp(prev_ch, prev_ch, 3))\n","        current_ch = prev_ch + skip_ch[-1]\n","        self.DB_up_1.append(DenseBlock(current_ch, kernel_s[0], padding, 2, 1, grow_rate, up_blocks[-1], False))\n","        current_ch += grow_rate*up_blocks[-1]\n","\n","        ########################\n","        #   Aux loss\n","        if self.training:\n","            self.aux = nn.Sequential(\n","                    nn.Conv2d(288, 256, kernel_size=3, padding=1, bias=False),\n","                    nn.BatchNorm2d(256),\n","                    nn.ReLU(inplace=True),\n","                    nn.Dropout2d(p=0.2),\n","                    nn.Conv2d(256, n_classes, kernel_size=1)\n","                )\n","        self.finalConv = nn.Conv2d(in_channels=current_ch, out_channels=n_classes,\n","                                   kernel_size=1, stride=1, padding=0, bias=True)\n","    def forward(self, x, y=None):\n","        _,_,h,w = x.size()\n","\n","        x_out = self.first_conv(x)\n","        skip_connections = []\n","        aux_in = None\n","        x_out_1 = x_out\n","\n","        for i in range(len(self.down_blocks)):\n","            x_out_1 = self.DB_down_1[i](x_out_1)\n","            skip = x_out_1\n","            skip_connections.append(skip)\n","\n","            x_out_1 = self.TD_1[i](x_out_1)\n","            if i == 2:\n","                aux_in = x_out_1\n","\n","        x_out_1 = self.bottleneck(x_out_1)\n","\n","        for i in range(len(self.up_blocks)):\n","            # Gate 1\n","            skip = skip_connections.pop()\n","            x_out_1 = self.TU_1[i](x_out_1, skip)\n","            x_out_1 = self.DB_up_1[i](x_out_1)\n","        x_out = x_out_1\n","        return x_out, aux_in\n","        # x_out = self.finalConv(x_out_1)\n","        # if self.training:\n","        #     aux = self.aux(aux_in)\n","        #     aux = F.interpolate(aux, size=(h, w), mode='bilinear', align_corners=True)\n","        #     aux_loss = self.criterion(aux, y)\n","        #     main_loss = self.criterion(x_out, y)\n","        #     return x_out, aux_loss, main_loss\n","        # else:\n","        #    return x_out\n"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1693298807906,"user":{"displayName":"Thái Bảo Nguyễn","userId":"10464131796033627061"},"user_tz":-420},"id":"QGKZt5pqmjbi"},"outputs":[],"source":["def conv3x3(in_ch, out_ch, stride=1):\n","    \"\"\"3x3 convolution with padding\"\"\"\n","    return nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=stride,\n","                     padding=1, bias=False)\n","\n","\n","class BasicBlock(nn.Module):\n","    expansion = 1\n","    def __init__(self, in_ch, out_ch, stride=1, downsample=None):\n","        super(BasicBlock, self).__init__()\n","        self.conv1 = conv3x3(in_ch, out_ch, stride)\n","        self.bn1 = nn.BatchNorm2d(out_ch)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.conv2 = conv3x3(out_ch, out_ch)\n","        self.bn2 = nn.BatchNorm2d(out_ch)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        residual = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","\n","        out += residual\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class Bottleneck(nn.Module):\n","    expansion = 4\n","    def __init__(self, in_ch, out_ch, stride=1, downsample=None):\n","        super(Bottleneck, self).__init__()\n","        self.conv1 = nn.Conv2d(in_ch, out_ch, kernel_size=1, bias=False)\n","        self.bn1 = nn.BatchNorm2d(out_ch)\n","        self.conv2 = nn.Conv2d(out_ch, out_ch, kernel_size=3, stride=stride,\n","                               padding=1, bias=False)\n","        self.bn2 = nn.BatchNorm2d(out_ch)\n","        self.conv3 = nn.Conv2d(out_ch, out_ch * self.expansion, kernel_size=1, bias=False)\n","        self.bn3 = nn.BatchNorm2d(out_ch * self.expansion)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.downsample = downsample\n","        self.stride = stride\n","\n","    def forward(self, x):\n","        residual = x\n","\n","        out = self.conv1(x)\n","        out = self.bn1(out)\n","        out = self.relu(out)\n","\n","        out = self.conv2(out)\n","        out = self.bn2(out)\n","        out = self.relu(out)\n","\n","        out = self.conv3(out)\n","        out = self.bn3(out)\n","\n","        if self.downsample is not None:\n","            residual = self.downsample(x)\n","\n","        out += residual\n","        out = self.relu(out)\n","\n","        return out\n","\n","\n","class ResNet(nn.Module):\n","    def __init__(self, block, layers, num_classes=1000, deep_base=True):\n","        super(ResNet, self).__init__()\n","        self.deep_base = deep_base\n","        if not self.deep_base:\n","            self.in_ch = 64\n","            self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n","            self.bn1 = nn.BatchNorm2d(64)\n","        else:\n","            self.in_ch = 128\n","            self.conv1 = conv3x3(3, 64, stride=2)\n","            self.bn1 = nn.BatchNorm2d(64)\n","            self.conv2 = conv3x3(64, 64)\n","            self.bn2 = nn.BatchNorm2d(64)\n","            self.conv3 = conv3x3(64, 128)\n","            self.bn3 = nn.BatchNorm2d(128)\n","        self.relu = nn.ReLU(inplace=True)\n","        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n","        self.layer1 = self._make_layer(block, 64, layers[0])\n","        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n","        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n","        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n","        self.avgpool = nn.AvgPool2d(7, stride=1)\n","        self.fc = nn.Linear(512 * block.expansion, num_classes)\n","\n","        for m in self.modules():\n","            if isinstance(m, nn.Conv2d):\n","                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n","            elif isinstance(m, nn.BatchNorm2d):\n","                nn.init.constant_(m.weight, 1)\n","                nn.init.constant_(m.bias, 0)\n","\n","    def _make_layer(self, block, out_ch, blocks, stride=1):\n","        downsample = None\n","        if stride != 1 or self.in_ch != out_ch * block.expansion:\n","            downsample = nn.Sequential(\n","                nn.Conv2d(self.in_ch, out_ch * block.expansion,\n","                          kernel_size=1, stride=stride, bias=False),\n","                nn.BatchNorm2d(out_ch * block.expansion),\n","            )\n","\n","        layers = []\n","        layers.append(block(self.in_ch, out_ch, stride, downsample))\n","        self.in_ch = out_ch * block.expansion\n","        for i in range(1, blocks):\n","            layers.append(block(self.in_ch, out_ch))\n","\n","        return nn.Sequential(*layers)\n","\n","    def forward(self, x):\n","        x = self.relu(self.bn1(self.conv1(x)))\n","        if self.deep_base:\n","            x = self.relu(self.bn2(self.conv2(x)))\n","            x = self.relu(self.bn3(self.conv3(x)))\n","        x = self.maxpool(x)\n","\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x = self.layer3(x)\n","        x = self.layer4(x)\n","\n","        x = self.avgpool(x)\n","        x = x.view(x.size(0), -1)\n","        x = self.fc(x)\n","\n","        return x\n","\n","\n","def resnet152(pretrained=True, **kwargs):\n","    \"\"\"Constructs a ResNet-152 model.\n","    Args:\n","        pretrained (bool): If True, returns a model pre-trained on ImageNet\n","    \"\"\"\n","    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n","    if pretrained:\n","        # model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n","        model_path = '/content/drive/MyDrive/Colab/resnet152_v2.pth'\n","        model.load_state_dict(torch.load(model_path), strict=False)\n","    return model"]},{"cell_type":"code","execution_count":11,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1693298807906,"user":{"displayName":"Thái Bảo Nguyễn","userId":"10464131796033627061"},"user_tz":-420},"id":"dFVvo1ZImjbj"},"outputs":[],"source":["class PPM(nn.Module):\n","    def __init__(self, in_ch, out_ch, bins):\n","        super(PPM, self).__init__()\n","        self.features = []\n","        for bin in bins:\n","            self.features.append(nn.Sequential(\n","                nn.AdaptiveAvgPool2d(bin),\n","                nn.Conv2d(in_ch, out_ch, kernel_size=1, bias=False),\n","                nn.BatchNorm2d(out_ch),\n","                nn.ReLU(inplace=True)\n","            ))\n","        self.features = nn.ModuleList(self.features)\n","\n","    def forward(self, x):\n","        x_size = x.size()\n","        out = [x]\n","        for f in self.features:\n","            out.append(F.interpolate(f(x), x_size[2:], mode='bilinear', align_corners=True))\n","        return torch.cat(out, 1)\n","\n","class PSPNet(nn.Module):\n","    def __init__(self, bins=(1, 2, 3, 6), dropout=0.15, classes=6, zoom_factor=8, use_ppm=True, criterion=nn.CrossEntropyLoss(ignore_index=255), pretrained=True):\n","        super(PSPNet, self).__init__()\n","        assert 2048 % len(bins) == 0\n","        assert classes > 1\n","        assert zoom_factor in [1, 2, 4, 8]\n","        self.zoom_factor = zoom_factor\n","        self.use_ppm = use_ppm\n","        self.criterion = criterion\n","\n","        resnet = resnet152(pretrained=True)\n","        self.layer0 = nn.Sequential(resnet.conv1, resnet.bn1, resnet.relu, resnet.conv2, resnet.bn2, resnet.relu,\n","                                    resnet.conv3, resnet.bn3, resnet.relu, resnet.maxpool)\n","        self.layer1, self.layer2, self.layer3, self.layer4 = resnet.layer1, resnet.layer2, resnet.layer3, resnet.layer4\n","\n","        for n, m in self.layer3.named_modules():\n","            if 'conv2' in n:\n","                m.dilation, m.padding, m.stride = (2, 2), (2, 2), (1, 1)\n","            elif 'downsample.0' in n:\n","                m.stride = (1, 1)\n","        for n, m in self.layer4.named_modules():\n","            if 'conv2' in n:\n","                m.dilation, m.padding, m.stride = (4, 4), (4, 4), (1, 1)\n","            elif 'downsample.0' in n:\n","                m.stride = (1, 1)\n","\n","        fea_dim = 2048\n","        if use_ppm:\n","            self.ppm = PPM(fea_dim, int(fea_dim/len(bins)), bins)\n","            fea_dim *= 2\n","\n","        self.cls = nn.Sequential(\n","            nn.Conv2d(fea_dim, 512, kernel_size=3, padding='same', dilation=2, stride=1, bias=False),\n","            nn.BatchNorm2d(512),\n","            nn.ReLU(inplace=True),\n","            nn.Dropout2d(p=dropout),\n","        )\n","\n","    def forward(self, x, y=None):\n","        x_size = x.size()\n","        assert (x_size[2]-1) % 8 == 0 and (x_size[3]-1) % 8 == 0\n","        h = int((x_size[2] - 1) / 8 * self.zoom_factor + 1)\n","        w = int((x_size[3] - 1) / 8 * self.zoom_factor + 1)\n","\n","        x = self.layer0(x)\n","        x = self.layer1(x)\n","        x = self.layer2(x)\n","        x_tmp = self.layer3(x)\n","        x = self.layer4(x_tmp)\n","        if self.use_ppm:\n","            x = self.ppm(x)\n","        x = self.cls(x)\n","        if self.zoom_factor != 1:\n","            x = F.interpolate(x, size=(h, w), mode='bilinear', align_corners=True)\n","        return x, x_tmp"]},{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1693298807906,"user":{"displayName":"Thái Bảo Nguyễn","userId":"10464131796033627061"},"user_tz":-420},"id":"wloA1SZamjbk"},"outputs":[],"source":["class MyModel(nn.Module):\n","    def __init__(self, n_classes=6):\n","        super(MyModel, self).__init__()\n","        self.criterion=nn.CrossEntropyLoss(ignore_index=255)\n","        self.pspnet = PSPNet()\n","        self.MPB = MPB_FCDenseNet()\n","        if self.training:\n","            self.aux = nn.Sequential(\n","                nn.Conv2d(1312, 256, kernel_size=3, padding=1, bias=False),\n","                nn.BatchNorm2d(256),\n","                nn.ReLU(inplace=True),\n","                nn.Dropout2d(p=0.15),\n","                nn.Conv2d(256, n_classes, kernel_size=1)\n","            )\n","        self.finalConv = nn.Conv2d(in_channels=768, out_channels=n_classes,\n","                                    kernel_size=1, stride=1, padding=0, bias=True)\n","    def forward(self,x ,y=None):\n","        x_fcdense = center_crop(x, x.size(2)-1, x.size(3)-1)\n","        _, _, h, w = x.size()\n","        pspnet, pspnet_aux = self.pspnet(x)\n","        fcdense, fcdense_aux = self.MPB(x_fcdense)\n","\n","        pspnet_aux = center_crop(pspnet_aux, pspnet_aux.size(2)-1, pspnet_aux.size(3)-1)\n","        pspnet = center_crop(pspnet, pspnet.size(2)-1, pspnet.size(3)-1)\n","\n","        x_out = torch.cat([pspnet, fcdense], dim=1)\n","        aux_in = torch.cat([pspnet_aux, fcdense_aux], dim=1)\n","\n","        x_out = F.interpolate(x_out, size=(h, w), mode='bilinear', align_corners=True)\n","        x_out = self.finalConv(x_out)\n","        if self.training:\n","            aux = self.aux(aux_in)\n","            aux = F.interpolate(aux, size=(h, w), mode='bilinear', align_corners=True)\n","            aux_loss = self.criterion(aux, y)\n","            main_loss = self.criterion(x_out, y)\n","            return x_out.max(1)[1], main_loss, aux_loss\n","        else:\n","           return x_out"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":7,"status":"ok","timestamp":1693298807906,"user":{"displayName":"Thái Bảo Nguyễn","userId":"10464131796033627061"},"user_tz":-420},"id":"7wWnReOPnKrZ"},"outputs":[],"source":["class Gleason(Dataset):\n","    def __init__(self, imgdir, maskdir=None, train=True, val=False,\n","                 test=False, transform=None, target_transform=None):\n","        super(Gleason, self).__init__()\n","        self.imgdir = imgdir\n","        self.maskdir = maskdir\n","        self.imglist = sorted(os.listdir(imgdir))\n","\n","        if not test:\n","            self.masklist = [item.replace('.jpg', '_classimg_nonconvex.png') for item in self.imglist]\n","        else:\n","            self.masklist = []\n","\n","        self.train = train\n","        self.val = val\n","        self.test = test\n","        self.transform = transform\n","        self.target_transform = target_transform\n","\n","    def __len__(self):\n","        return len(self.imglist)\n","\n","    def __getitem__(self, idx):\n","        image = np.array(Image.open(osp.join(self.imgdir, self.imglist[idx])))\n","        if self.test == True:\n","            transformed = self.transform(image=image)\n","            image = transformed[\"image\"]\n","            return image\n","\n","        mask = np.array(Image.open(osp.join(self.maskdir, self.masklist[idx])))\n","        if self.transform:\n","            transformed = self.transform(image=image, mask=mask)\n","            image = transformed[\"image\"]\n","            mask = transformed[\"mask\"]\n","        if self.target_transform:\n","            mask = self.target_transform(mask)\n","        return image, mask"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1693298807907,"user":{"displayName":"Thái Bảo Nguyễn","userId":"10464131796033627061"},"user_tz":-420},"id":"n5n2D4XvnMVJ"},"outputs":[],"source":["def get_dataset(imgdir, maskdir=None, train=True, val=False, test=False,\n","                transform=None, target_transform=None):\n","    dataset = Gleason(imgdir=imgdir, maskdir=maskdir, train=train,\n","                      val=val, test=test, transform=transform, target_transform=target_transform)\n","    return dataset\n","\n","\n","def get_transform(train):\n","    if train:\n","        return A.Compose([\n","            A.Resize(width=257, height=257),\n","            A.HorizontalFlip(),\n","            A.RandomBrightnessContrast(),\n","            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0),\n","            ToTensorV2(),\n","        ])\n","    else:\n","        return A.Compose([\n","        A.Resize(width=257, height=257),\n","        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0),\n","        ToTensorV2(), # numpy.array -> torch.tensor (B, 3, H, W)\n","        ])\n"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1693298807907,"user":{"displayName":"Thái Bảo Nguyễn","userId":"10464131796033627061"},"user_tz":-420},"id":"hxSsgIFvnNof"},"outputs":[],"source":["class UnNormalize(object):\n","    def __init__(self, mean, std):\n","        self.mean = mean\n","        self.std = std\n","\n","    def __call__(self, tensor):\n","        \"\"\"\n","        Args:\n","            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n","        Returns:\n","            Tensor: Normalized image.\n","        \"\"\"\n","        for t, m, s in zip(tensor, self.mean, self.std):\n","            t.mul_(s).add_(m)\n","            # The normalize code -> t.sub_(m).div_(s)\n","        return tensor\n","\n","unorm = UnNormalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n","\n","class AverageMeter(object):\n","    def __init__(self):\n","        self.reset()\n","\n","    def reset(self):\n","        self.val = 0\n","        self.avg = 0\n","        self.sum = 0\n","        self.count = 0\n","\n","    def update(self, val, n=1):\n","        self.val = val\n","        self.sum += val * n\n","        self.count += n\n","        self.avg = self.sum / self.count"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":8,"status":"ok","timestamp":1693298807907,"user":{"displayName":"Thái Bảo Nguyễn","userId":"10464131796033627061"},"user_tz":-420},"id":"fHYrIGs3nOyl"},"outputs":[],"source":["#metrics\n","def intersectionAndUnionGPU(output, target, K, ignore_index=255):\n","    # 'K' classes, output and target sizes are N or N * L or N * H * W, each value in range 0 to K - 1.\n","    assert output.shape == target.shape\n","    output = output.view(-1)\n","    target = target.view(-1)\n","    output[target == ignore_index] = ignore_index\n","    intersection = output[output == target]\n","    area_intersection = torch.histc(intersection, bins=K, min=0, max=K-1)\n","    area_output = torch.histc(output, bins=K, min=0, max=K-1)\n","    area_target = torch.histc(target, bins=K, min=0, max=K-1)\n","    area_union = area_output + area_target - area_intersection\n","    return area_intersection, area_union, area_target"]},{"cell_type":"code","execution_count":17,"metadata":{"id":"jw-cnaURnRLV","executionInfo":{"status":"ok","timestamp":1693298835304,"user_tz":-420,"elapsed":27404,"user":{"displayName":"Thái Bảo Nguyễn","userId":"10464131796033627061"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"8c91598f-d861-4b44-a9e8-20fc3a221fb5"},"outputs":[{"output_type":"stream","name":"stdout","text":["num_workers = 8\n"]}],"source":["#device\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","\n","#load data\n","batch_size = 5\n","n_workers = os.cpu_count()\n","print(\"num_workers =\", n_workers)\n","train_dataset = get_dataset(imgdir='/content/drive/MyDrive/MyProject/Train_cropped_8',\n","                        maskdir='/content/drive/MyDrive/MyProject/Mask_cropped_8',\n","                        train=True, val=False, test=False, transform=get_transform(train=False))\n","\n","trainloader = DataLoader(train_dataset, batch_size=batch_size,\n","                                          shuffle=True, num_workers=n_workers)\n","\n","#model\n","model = MyModel().to(device)\n","\n","#loss\n","criterion = nn.CrossEntropyLoss(ignore_index=255)\n","\n","#optimizer\n","base_lr = 1e-3\n","n_eps = 21\n","optimizer = torch.optim.SGD(model.parameters(), lr=base_lr, momentum=0.9, weight_decay=1e-4)\n","lr_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lambda x: (1 - x / (len(trainloader) * n_eps)) ** 0.9)\n","\n","#meter\n","train_loss_meter = AverageMeter()\n","intersection_meter = AverageMeter()\n","union_meter = AverageMeter()\n","target_meter = AverageMeter()"]},{"cell_type":"code","source":["max_batch = len(os.listdir('/content/drive/MyDrive/MyProject/Train_cropped_8'))//2\n","max_batch"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HDSGn711JlUz","executionInfo":{"status":"ok","timestamp":1693298835305,"user_tz":-420,"elapsed":6,"user":{"displayName":"Thái Bảo Nguyễn","userId":"10464131796033627061"}},"outputId":"e44f2c62-aec6-4d5a-a363-98723c893805"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["1289"]},"metadata":{},"execution_count":18}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"fpY46s2CnSb8","colab":{"base_uri":"https://localhost:8080/"},"outputId":"ef350343-14e6-4ce4-c00f-6cf5d38d31d7"},"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 645/645 [06:04<00:00,  1.77it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","EP 1, train loss = 1.389914178386215, mIoU = 0.2549999952316284, mDice = 0.3580000102519989\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 645/645 [04:59<00:00,  2.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","EP 2, train loss = 1.1560389695703521, mIoU = 0.3240000009536743, mDice = 0.43299999833106995\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 645/645 [05:00<00:00,  2.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","EP 3, train loss = 1.0329085405482803, mIoU = 0.37599998712539673, mDice = 0.4950000047683716\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 645/645 [05:00<00:00,  2.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","EP 4, train loss = 0.9211631573909937, mIoU = 0.45399999618530273, mDice = 0.5789999961853027\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 645/645 [04:59<00:00,  2.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","EP 5, train loss = 0.825453359928242, mIoU = 0.5, mDice = 0.6200000047683716\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 645/645 [04:59<00:00,  2.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","EP 6, train loss = 0.7332797919363938, mIoU = 0.5569999814033508, mDice = 0.6660000085830688\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 645/645 [05:00<00:00,  2.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","EP 7, train loss = 0.9408440104750699, mIoU = 0.45500001311302185, mDice = 0.5830000042915344\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 645/645 [04:59<00:00,  2.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","EP 8, train loss = 0.8466503408297088, mIoU = 0.5, mDice = 0.621999979019165\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 645/645 [05:00<00:00,  2.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","EP 9, train loss = 0.7594469275354415, mIoU = 0.5339999794960022, mDice = 0.6480000019073486\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 645/645 [04:59<00:00,  2.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","EP 10, train loss = 0.7086426886477212, mIoU = 0.5580000281333923, mDice = 0.6660000085830688\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 645/645 [04:59<00:00,  2.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","EP 11, train loss = 0.6696290494397629, mIoU = 0.5699999928474426, mDice = 0.675000011920929\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 645/645 [04:59<00:00,  2.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","EP 12, train loss = 0.6122102198674697, mIoU = 0.6140000224113464, mDice = 0.7059999704360962\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 645/645 [05:00<00:00,  2.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","EP 13, train loss = 0.5437817117271497, mIoU = 0.6349999904632568, mDice = 0.7200000286102295\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 645/645 [05:00<00:00,  2.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","EP 14, train loss = 0.5013113162314244, mIoU = 0.6669999957084656, mDice = 0.7409999966621399\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 645/645 [05:00<00:00,  2.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","EP 15, train loss = 0.4722265360660331, mIoU = 0.6669999957084656, mDice = 0.7400000095367432\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 645/645 [04:59<00:00,  2.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","EP 16, train loss = 0.44680915851463643, mIoU = 0.6840000152587891, mDice = 0.7509999871253967\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 645/645 [04:59<00:00,  2.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","EP 17, train loss = 0.418000176756881, mIoU = 0.6869999766349792, mDice = 0.753000020980835\n"]},{"output_type":"stream","name":"stderr","text":["100%|██████████| 645/645 [04:59<00:00,  2.15it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","EP 18, train loss = 0.4194678149251051, mIoU = 0.6959999799728394, mDice = 0.7580000162124634\n"]},{"output_type":"stream","name":"stderr","text":[" 11%|█         | 68/645 [00:32<04:27,  2.16it/s]"]}],"source":["start_time = time.time()\n","#training script\n","for ep in range(1, n_eps):\n","    train_loss_meter.reset()\n","    intersection_meter.reset()\n","    union_meter.reset()\n","    target_meter.reset()\n","    model.train()\n","    max_iter = n_eps * len(trainloader)\n","    if ep == 7:\n","      train_dataset_agu = get_dataset(imgdir='/content/drive/MyDrive/MyProject/Train_cropped_8',\n","                        maskdir='/content/drive/MyDrive/MyProject/Mask_cropped_8',\n","                        train=True, val=False, test=False, transform=get_transform(train=True))\n","      trainloader = DataLoader(train_dataset_agu, batch_size=batch_size, shuffle=True, num_workers=n_workers)\n","\n","    for batch_id, (x, y) in enumerate(tqdm(trainloader), start=1):\n","        if batch_id == max_batch - 1:\n","            break\n","        #qua trinh hoc mo hinh theo batch\n","        optimizer.zero_grad()\n","        n = x.shape[0]\n","        x = x.to(device).float()\n","        y = y.to(device).long()\n","        y_hat_mask, main_loss, aux_loss = model(x, y)\n","        loss = main_loss + aux_loss*0.4\n","        loss.backward()\n","        optimizer.step()\n","        lr_scheduler.step()\n","        #save metrics\n","        with torch.no_grad():\n","            train_loss_meter.update(loss.item())\n","            intersection, union, target = intersectionAndUnionGPU(y_hat_mask.float(), y.float(), 6)\n","            intersection_meter.update(intersection)\n","            union_meter.update(union)\n","            target_meter.update(target)\n","    #compute iou, dice\n","    with torch.no_grad():\n","        iou_class = intersection_meter.sum / (union_meter.sum + 1e-10) #vector 6D\n","        dice_class = (2 * intersection_meter.sum) / (intersection_meter.sum + union_meter.sum + 1e-10) #vector 6D\n","        mIoU = torch.round(torch.mean(iou_class), decimals=3) #mean vector 6D\n","        mDice = torch.round(torch.mean(dice_class), decimals=3) #mean vector 6D\n","\n","    print(f\"\\nEP {ep}, train loss = {train_loss_meter.avg}, mIoU = {mIoU}, mDice = {mDice}\")\n","\n","total_time = time.time() - start_time\n","total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n","print('Training time {}'.format(total_time_str))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"QtnYnCFVnT25"},"outputs":[],"source":["Val_train = get_dataset(imgdir='/content/drive/MyDrive/MyProject/Train_cropped_8_1',\n","                        maskdir='/content/drive/MyDrive/MyProject/Mask_cropped_8_1',\n","                        train=False,\n","                        val=True,\n","                        test=False,\n","                        transform=get_transform(train=False))\n","Valloader = torch.utils.data.DataLoader(Val_train, batch_size=batch_size,\n","                                          shuffle=False, num_workers=n_workers)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HzXb97irnU9n"},"outputs":[],"source":["model.eval()\n","test_intersection_meter = AverageMeter()\n","test_union_meter = AverageMeter()\n","test_target_meter = AverageMeter()\n","with torch.no_grad():\n","    for batch_id, (x, y) in enumerate(tqdm(Valloader), start=1):\n","        n = x.shape[0]\n","        x = x.to(device).float()\n","        y = y.to(device).long()\n","        y_hat = model(x)\n","        y_hat = y_hat.squeeze(1)\n","        y_hat_mask = y_hat.argmax(dim=1)\n","\n","        intersection, union, target = intersectionAndUnionGPU(y_hat_mask, y, 6)\n","        test_intersection_meter.update(intersection)\n","        test_union_meter.update(union)\n","        test_target_meter.update(target)\n","\n","    iou_class = test_intersection_meter.sum / (test_union_meter.sum + 1e-10)\n","    dice_class = 2*test_intersection_meter.sum / (test_intersection_meter.sum + test_union_meter.sum + 1e-10)\n","\n","    mIoU = torch.mean(iou_class)\n","    mDice = torch.mean(dice_class)\n","\n","print(\"TEST: IoU = {}, dice = {}\".format(mIoU, mDice))"]},{"cell_type":"code","source":["from torchvision import models\n","from torchsummary import summary\n","\n","\n","summary(model, (3, 257, 257))"],"metadata":{"id":"VM2PsUspfLha"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"provenance":[],"machine_shape":"hm","gpuType":"V100","cell_execution_strategy":"setup"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":0}