{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqNzVlhqMvBe",
        "outputId": "16236406-8e12-4f4a-e1bc-88ecdfbbe318"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "y4WomRKPMtUM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2 # np.array -> torch.tensor\n",
        "import os\n",
        "import os.path as osp\n",
        "from PIL import Image\n",
        "from torchvision import transforms as T\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "import datetime\n",
        "import time\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "import matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "JCzV4vVoMtUO"
      },
      "outputs": [],
      "source": [
        "def conv3x3(in_planes, out_planes, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_planes, out_planes, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(inplanes, planes, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(planes, planes)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, inplanes, planes, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(inplanes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, planes * self.expansion, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(planes * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes=1000, deep_base=True):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.deep_base = deep_base\n",
        "        if not self.deep_base:\n",
        "            self.inplanes = 64\n",
        "            self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "            self.bn1 = nn.BatchNorm2d(64)\n",
        "        else:\n",
        "            self.inplanes = 128\n",
        "            self.conv1 = conv3x3(3, 64, stride=2)\n",
        "            self.bn1 = nn.BatchNorm2d(64)\n",
        "            self.conv2 = conv3x3(64, 64)\n",
        "            self.bn2 = nn.BatchNorm2d(64)\n",
        "            self.conv3 = conv3x3(64, 128)\n",
        "            self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.bottleneck = Bottleneck(512, 128)\n",
        "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, block, planes, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.inplanes != planes * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.inplanes, planes * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(planes * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.inplanes, planes, stride, downsample))\n",
        "        self.inplanes = planes * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.inplanes, planes))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.bn1(self.conv1(x)))\n",
        "        if self.deep_base:\n",
        "            x = self.relu(self.bn2(self.conv2(x)))\n",
        "            x = self.relu(self.bn3(self.conv3(x)))\n",
        "        x = self.maxpool(x)\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "        x = self.bottleneck(x)\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "def resnet152(pretrained=True, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-152 model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        # model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n",
        "        model_path = './initmodel/resnet152_v2.pth'\n",
        "        model.load_state_dict(torch.load(model_path), strict=False)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-iVQGSrpMtUR"
      },
      "outputs": [],
      "source": [
        "class PPM(nn.Module):\n",
        "    def __init__(self, in_dim, reduction_dim, bins):\n",
        "        super(PPM, self).__init__()\n",
        "        self.features = []\n",
        "        for bin in bins:\n",
        "            self.features.append(nn.Sequential(\n",
        "                nn.AdaptiveAvgPool2d(bin),\n",
        "                nn.Conv2d(in_dim, reduction_dim, kernel_size=1, bias=False),\n",
        "                nn.BatchNorm2d(reduction_dim),\n",
        "                nn.ReLU(inplace=True)\n",
        "            ))\n",
        "        self.features = nn.ModuleList(self.features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_size = x.size()\n",
        "        out = [x]\n",
        "        for f in self.features:\n",
        "            out.append(F.interpolate(f(x), x_size[2:], mode='bilinear', align_corners=True))\n",
        "        return torch.cat(out, 1)\n",
        "\n",
        "class PSPNet(nn.Module):\n",
        "    def __init__(self, bins=(1, 2, 3, 6), dropout=0.15, n_classes=5, zoom_factor=8):\n",
        "        super(PSPNet, self).__init__()\n",
        "        assert 2048 % len(bins) == 0\n",
        "        assert n_classes > 1\n",
        "        assert zoom_factor in [1, 2, 4, 8]\n",
        "        self.zoom_factor = zoom_factor\n",
        "\n",
        "        resnet = resnet152(pretrained=False)\n",
        "        self.layer0_0 = nn.Sequential(resnet.conv1, resnet.bn1, resnet.relu)\n",
        "        self.layer0_1 = nn.Sequential(resnet.conv2, resnet.bn2, resnet.relu)\n",
        "        self.layer0_2 = nn.Sequential(resnet.conv3, resnet.bn3, resnet.relu,\n",
        "                                        resnet.maxpool)\n",
        "        self.layer1, self.layer2, self.layer3, self.layer4 = resnet.layer1, resnet.layer2, resnet.layer3, resnet.layer4\n",
        "\n",
        "        for n, m in self.layer3.named_modules():\n",
        "            if 'conv2' in n:\n",
        "                m.dilation, m.padding, m.stride = (2, 2), (2, 2), (1, 1)\n",
        "            elif 'downsample.0' in n:\n",
        "                m.stride = (1, 1)\n",
        "        for n, m in self.layer4.named_modules():\n",
        "            if 'conv2' in n:\n",
        "                m.dilation, m.padding, m.stride = (4, 4), (4, 4), (1, 1)\n",
        "            elif 'downsample.0' in n:\n",
        "                m.stride = (1, 1)\n",
        "\n",
        "        fea_dim = 2048\n",
        "        self.ppm = PPM(fea_dim, int(fea_dim/len(bins)), bins)\n",
        "        fea_dim *= 2\n",
        "\n",
        "        self.cls = nn.Sequential(\n",
        "            nn.Conv2d(fea_dim, 512, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(512, 256, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(p=dropout),\n",
        "        )\n",
        "\n",
        "        self.conv1_1 = nn.Sequential(nn.Conv2d(256, 48, kernel_size=1, padding=0, stride=1, bias=False),\n",
        "                                    nn.BatchNorm2d(48),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(48, 48, kernel_size=1, padding=0, stride=1, bias=False),\n",
        "                                    nn.BatchNorm2d(48),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Conv2d(48, 256, kernel_size=1, padding=0, stride=1, bias=False),\n",
        "                                    nn.BatchNorm2d(256),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Dropout2d(p=dropout),\n",
        "                )\n",
        "\n",
        "\n",
        "    def forward(self, x, y=None):\n",
        "        x_size = x.size()\n",
        "        assert (x_size[2]-1) % 8 == 0 and (x_size[3]-1) % 8 == 0\n",
        "        h = int((x_size[2] - 1) / 8 * self.zoom_factor + 1)\n",
        "        w = int((x_size[3] - 1) / 8 * self.zoom_factor + 1)\n",
        "        x0 = self.layer0_0(x)\n",
        "        x0 = self.layer0_1(x0)\n",
        "        x0 = self.layer0_2(x0)\n",
        "        x1 = self.layer1(x0)\n",
        "        x2 = self.layer2(x1)\n",
        "        x3 = self.layer3(x2)\n",
        "        x4 = self.layer4(x3)\n",
        "        x_ppm = self.ppm(x4)\n",
        "        x = self.cls(x_ppm)\n",
        "        x_conv1_1 = self.conv1_1(x1)\n",
        "\n",
        "        return x, x_conv1_1, x3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Zqa_yEFZMtUS"
      },
      "outputs": [],
      "source": [
        "# model = PSPNet()\n",
        "# x = torch.rand(4, 3, 257, 257)\n",
        "\n",
        "# y, conv1_1, aux = model(x)\n",
        "# print('=======')\n",
        "# print(y.size())\n",
        "# print(conv1_1.size())\n",
        "# print(aux.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "HkxYLB18MtUS"
      },
      "outputs": [],
      "source": [
        "class Layer(nn.Module):\n",
        "    def __init__(self, in_ch, kernel_s=3, padding=1, stride=1, grow_rate=16, dropRate=0.2):\n",
        "        super(Layer, self).__init__()\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.bn = nn.BatchNorm2d(in_ch)\n",
        "        self.conv = nn.Conv2d(in_ch, grow_rate, kernel_size=kernel_s, stride=stride,\n",
        "                               padding=padding, bias=False)\n",
        "        self.droprate = nn.Dropout(p=dropRate)\n",
        "    def forward(self, x):\n",
        "        x_out = self.conv(self.relu(self.bn(x)))\n",
        "        x_out = self.droprate(x_out)\n",
        "        return x_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "s8fEanFNMtUT"
      },
      "outputs": [],
      "source": [
        "class DenseBlock(nn.Module):\n",
        "    def __init__(self, in_ch, kernel_s=3, padding=1, stride=1, grow_rate=16, n_layers=4, Upsample=False):\n",
        "        super(DenseBlock, self).__init__()\n",
        "        self.upsample = Upsample\n",
        "        self.layers = nn.ModuleList([Layer(in_ch + i*grow_rate, kernel_s, padding, stride, grow_rate)\n",
        "                                     for i in range(n_layers)])\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.upsample:\n",
        "            new_features = []\n",
        "            for layer in self.layers:\n",
        "                x_out = layer(x)\n",
        "                x = torch.cat([x, x_out], 1)\n",
        "                new_features.append(x_out)\n",
        "            return torch.cat(new_features,1)\n",
        "        else:\n",
        "            layer_arr = [x]\n",
        "            for i in range(self.n_layers):\n",
        "                x_out = self.layers[i](x)\n",
        "                layer_arr.append(x_out)\n",
        "                if i == self.n_layers - 1:\n",
        "                    x = torch.cat(layer_arr, 1)\n",
        "                else:\n",
        "                    x = torch.cat([x, x_out], 1)\n",
        "            return x\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2xH3Lns6MtUT"
      },
      "outputs": [],
      "source": [
        "class TransitionDown(nn.Module):\n",
        "    def __init__(self, in_ch, dropRate=0.15):\n",
        "        super(TransitionDown, self).__init__()\n",
        "        self.bn = nn.BatchNorm2d(in_ch)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv = nn.Conv2d(in_ch, in_ch, kernel_size=1, stride=1, padding=1, bias=False)\n",
        "        self.pooling =  nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.droprate = nn.Dropout(p=dropRate)\n",
        "    def forward(self, x):\n",
        "        x_out = self.conv(self.relu(self.bn(x)))\n",
        "        x_out = self.droprate(x_out)\n",
        "        x_out = self.pooling(x_out)\n",
        "        return x_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "UulRk4-KMtUT"
      },
      "outputs": [],
      "source": [
        "def center_crop(layer, max_height, max_width):\n",
        "    _, _, h, w = layer.size()\n",
        "    xy1 = (w - max_width) // 2\n",
        "    xy2 = (h - max_height) // 2\n",
        "    return layer[:, :, xy2:(xy2 + max_height), xy1:(xy1 + max_width)]\n",
        "\n",
        "class TransitionUp(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, kernel_s=3, skip=True, padding=0):\n",
        "        super(TransitionUp, self).__init__()\n",
        "        self.transpose = nn.ConvTranspose2d(in_ch, out_ch, kernel_size=kernel_s, stride=2, padding=padding, bias=True)\n",
        "        self.skip = skip\n",
        "    def forward(self, x, skip_connection):\n",
        "        x_out = self.transpose(x)\n",
        "        if self.skip == True:\n",
        "            x_out = center_crop(x_out, skip_connection.size(2), skip_connection.size(3))\n",
        "            x_out = torch.cat([x_out, skip_connection], 1)\n",
        "        return x_out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "1gis2mwVMtUT"
      },
      "outputs": [],
      "source": [
        "class FCDenseNet(nn.Module):\n",
        "    def __init__(self, in_ch=3, down_blocks=(5, 5, 5, 5, 5),\n",
        "                 up_blocks=(5, 5, 5), bottleneck_layers=5,\n",
        "                 grow_rate=16, kernel_s=3, padding=1, dilation=1, stride=1, m=48, n_classes=5):\n",
        "        super(FCDenseNet, self).__init__()\n",
        "        self.down_blocks = down_blocks\n",
        "        self.up_blocks = up_blocks\n",
        "\n",
        "        #   First Convolution   #\n",
        "        #########################\n",
        "        self.first_conv = nn.Conv2d(in_channels=in_ch, out_channels=m, kernel_size=3, stride=1, padding=1, bias=True)\n",
        "        #########################################################################\n",
        "        #############################   Multi Gate  #############################\n",
        "        current_ch = m\n",
        "        skip_ch = []\n",
        "        #   Downsampling    #\n",
        "        #####################\n",
        "        self.DB_down_1 = nn.ModuleList([])\n",
        "        self.TD_1 = nn.ModuleList([])\n",
        "        for i in range(len(down_blocks)):\n",
        "            self.DB_down_1.append(DenseBlock(current_ch, kernel_s, padding, stride, grow_rate, down_blocks[i], False))\n",
        "            current_ch +=(down_blocks[i]*grow_rate)\n",
        "            if i > 1:\n",
        "                skip_ch.insert(0,current_ch)\n",
        "            self.TD_1.append(TransitionDown(current_ch))\n",
        "        #   bottleneck_1   #\n",
        "        ##################\n",
        "        # Layer : DB (15 layers), m = 896\n",
        "        self.bottleneck = DenseBlock(current_ch, kernel_s, padding, 1, grow_rate, bottleneck_layers, True)\n",
        "        prev_ch = (bottleneck_layers*grow_rate)\n",
        "        current_ch += prev_ch\n",
        "        #   Upsampling path   #\n",
        "        #######################\n",
        "        self.DB_up_1 = nn.ModuleList([])\n",
        "        self.TU_1 = nn.ModuleList([])\n",
        "        for i in range(len(up_blocks)-1):\n",
        "            kernel_tu = 3\n",
        "            self.TU_1.append(TransitionUp(prev_ch, prev_ch, kernel_tu))\n",
        "            current_ch = prev_ch + skip_ch[i]\n",
        "            self.DB_up_1.append(DenseBlock(current_ch, kernel_s, padding, 1, grow_rate, up_blocks[i], True))\n",
        "            prev_ch = grow_rate*up_blocks[i]\n",
        "            current_ch += prev_ch\n",
        "        #   Final DenseBlock    #\n",
        "        #########################\n",
        "        self.TU_1.append(TransitionUp(prev_ch, prev_ch, 3))\n",
        "        current_ch = prev_ch + skip_ch[-1]\n",
        "        self.DB_up_1.append(DenseBlock(current_ch, kernel_s, padding, 1, grow_rate, up_blocks[-1], False))\n",
        "        current_ch += grow_rate*up_blocks[-1]\n",
        "\n",
        "\n",
        "    def forward(self, x, y=None):\n",
        "        _,_,h,w = x.size()\n",
        "\n",
        "        x_out = self.first_conv(x)\n",
        "        skip_connections = []\n",
        "        aux_in = None\n",
        "\n",
        "        for i in range(len(self.down_blocks)):\n",
        "            x_out = self.DB_down_1[i](x_out)\n",
        "            skip_connections.append(x_out)\n",
        "            x_out = self.TD_1[i](x_out)\n",
        "            if i == 2:\n",
        "                aux_in = x_out\n",
        "\n",
        "        x_out = self.bottleneck(x_out)\n",
        "\n",
        "        for i in range(len(self.up_blocks)):\n",
        "            # Gate 1\n",
        "            skip = skip_connections.pop()\n",
        "            x_out = self.TU_1[i](x_out, skip)\n",
        "            x_out = self.DB_up_1[i](x_out)\n",
        "\n",
        "        return x_out, aux_in\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "pxNXGnNWMtUU"
      },
      "outputs": [],
      "source": [
        "# model = FCDenseNet()\n",
        "# x = torch.rand(4, 3, 256, 256)\n",
        "\n",
        "# y, aux = model(x)\n",
        "# print('===========')\n",
        "# print(y.size())\n",
        "# print(aux.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "I62atajJMtUU"
      },
      "outputs": [],
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, n_classes=6, dropout=0.15,):\n",
        "        super(Model, self).__init__()\n",
        "        self.pspnet = PSPNet(n_classes=n_classes)\n",
        "        self.fcdense = FCDenseNet(n_classes=n_classes)\n",
        "\n",
        "        self.p_upsampling = TransitionUp(256, 256, 3, False, padding=1)\n",
        "        self.ASC1 = nn.Sequential(\n",
        "                                nn.Conv2d(960, 256, kernel_size=3, stride=1, padding=1, dilation=1, bias=False),\n",
        "                                nn.BatchNorm2d(256),\n",
        "                                nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.ASC2 = nn.Sequential(\n",
        "                                nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, dilation=1, bias=False),\n",
        "                                nn.BatchNorm2d(256),\n",
        "                                nn.ReLU(inplace=True)\n",
        "        )\n",
        "        self.finalconv = nn.Sequential(\n",
        "                                nn.Conv2d(256, 256, kernel_size=3, stride=1, padding=1, bias=False),\n",
        "                                nn.BatchNorm2d(256),\n",
        "                                nn.ReLU(inplace=True),\n",
        "                                nn.Dropout(p=dropout),\n",
        "                                nn.Conv2d(256, n_classes, kernel_size=1, stride=1, padding=0, bias=False)\n",
        "        )\n",
        "\n",
        "\n",
        "        class_weights= torch.tensor([0.348, 3.786, 0, 1.394, 0.893, 37.098] ,dtype=torch.float)\n",
        "        self.criterion= nn.CrossEntropyLoss(ignore_index=255, weight=class_weights)\n",
        "        if self.training:\n",
        "            self.aux = nn.Sequential(\n",
        "                nn.Conv2d(1312, 256, kernel_size=3, padding=1, bias=False),\n",
        "                nn.BatchNorm2d(256),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout2d(p=0.15),\n",
        "                nn.Conv2d(256, n_classes, kernel_size=1)\n",
        "            )\n",
        "    def forward(self, x, y=None):\n",
        "        _, _, h, w = x.size()\n",
        "        x_p = F.interpolate(x, size=(h+1, w+1), mode='bilinear', align_corners=True)\n",
        "        p_out, p_conv1, p_aux = self.pspnet(x_p)\n",
        "        d_out, d_aux = self.fcdense(x)\n",
        "        # print(f'p out: {p_out.size()}')\n",
        "        # print(f'p conv1: {p_conv1.size()}')\n",
        "\n",
        "        # print(f'd out: {d_out.size()}')\n",
        "        p_out = self.p_upsampling(p_out, None)\n",
        "        #print(f'p out: {p_out.size()}')\n",
        "\n",
        "        out = torch.cat([p_out, p_conv1, d_out], 1)\n",
        "        #print(f'out: {out.size()}')\n",
        "        out = self.ASC1(out)\n",
        "        #print(f'out: {out.size()}')\n",
        "        out = self.ASC2(out)\n",
        "        #print(f'out: {out.size()}')\n",
        "        out = self.finalconv(out)\n",
        "        #print(f'out: {out.size()}')\n",
        "\n",
        "        out = F.interpolate(out, size=(256, 256), mode='bilinear', align_corners=True)\n",
        "        #print(out.size())\n",
        "        if self.training:\n",
        "            aux_in = torch.cat([p_aux, d_aux], 1)\n",
        "            aux = self.aux(aux_in)\n",
        "            aux = F.interpolate(aux, size=(h, w), mode='bilinear', align_corners=True)\n",
        "            aux_loss = self.criterion(aux, y)\n",
        "            main_loss = self.criterion(out, y)\n",
        "            return out.max(1)[1], main_loss, aux_loss\n",
        "        else:\n",
        "           return out"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "qUtY1fZPOAIY"
      },
      "outputs": [],
      "source": [
        "class Gleason(Dataset):\n",
        "    def __init__(self, imgdir, maskdir=None, train=True, val=False,\n",
        "                 test=False, transform=None, target_transform=None):\n",
        "        super(Gleason, self).__init__()\n",
        "        self.imgdir = imgdir\n",
        "        self.maskdir = maskdir\n",
        "        self.imglist = os.listdir(imgdir)\n",
        "        if not test:\n",
        "            self.masklist = [item.replace('.jpg', '_classimg_nonconvex.png') for item in self.imglist]\n",
        "        else:\n",
        "            self.masklist = []\n",
        "\n",
        "        self.train = train\n",
        "        self.val = val\n",
        "        self.test = test\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imglist)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = np.array(Image.open(f'{self.imgdir}/{self.imglist[idx]}'))\n",
        "        if self.test == True:\n",
        "            transformed = self.transform(image=image)\n",
        "            image = transformed[\"image\"]\n",
        "            return image\n",
        "        mask = np.array(Image.open(f'{self.maskdir}/{self.masklist[idx]}'))\n",
        "        if self.transform:\n",
        "            transformed = self.transform(image=image, mask=mask)\n",
        "            image = transformed[\"image\"]\n",
        "            mask = transformed[\"mask\"]\n",
        "        if self.target_transform:\n",
        "            mask = self.target_transform(mask)\n",
        "        return image, mask"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-_UI3yo6OAnq"
      },
      "outputs": [],
      "source": [
        "def get_dataset(imgdir, maskdir=None, train=True, val=False, test=False,\n",
        "                transform=None, target_transform=None):\n",
        "    dataset = Gleason(imgdir=imgdir, maskdir=maskdir, train=train,\n",
        "                      val=val, test=test, transform=transform, target_transform=target_transform)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def get_transform(train):\n",
        "    if train:\n",
        "        return A.Compose([\n",
        "            A.Resize(width=256, height=256, interpolation=cv2.INTER_LINEAR),\n",
        "            A.HorizontalFlip(),\n",
        "            A.geometric.rotate.Rotate(limit=(-15, -15), value=(255,255,255), p=1),\n",
        "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0),\n",
        "            ToTensorV2(),\n",
        "        ])\n",
        "    else:\n",
        "        return A.Compose([\n",
        "        A.Resize(width=256, height=256, interpolation=cv2.INTER_LINEAR),\n",
        "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0),\n",
        "        ToTensorV2(), # numpy.array -> torch.tensor (B, 3, H, W)\n",
        "        ])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "4G721k7wOByb"
      },
      "outputs": [],
      "source": [
        "class UnNormalize(object):\n",
        "    def __init__(self, mean, std):\n",
        "        self.mean = mean\n",
        "        self.std = std\n",
        "\n",
        "    def __call__(self, tensor):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            tensor (Tensor): Tensor image of size (C, H, W) to be normalized.\n",
        "        Returns:\n",
        "            Tensor: Normalized image.\n",
        "        \"\"\"\n",
        "        for t, m, s in zip(tensor, self.mean, self.std):\n",
        "            t.mul_(s).add_(m)\n",
        "            # The normalize code -> t.sub_(m).div_(s)\n",
        "        return tensor\n",
        "\n",
        "unorm = UnNormalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))\n",
        "\n",
        "class AverageMeter(object):\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "SvCqH_Y6ODbc"
      },
      "outputs": [],
      "source": [
        "#metrics\n",
        "def intersectionAndUnionGPU(output, target, K, ignore_index=255):\n",
        "    # 'K' classes, output and target sizes are N or N * L or N * H * W, each value in range 0 to K - 1.\n",
        "    assert output.shape == target.shape\n",
        "    #output = output.view(-1)\n",
        "    #target = target.view(-1)\n",
        "    output[target == ignore_index] = ignore_index\n",
        "    intersection = output[output == target]\n",
        "    area_intersection = torch.histc(intersection, bins=K, min=0, max=K-1)\n",
        "    area_output = torch.histc(output, bins=K, min=0, max=K-1)\n",
        "    area_target = torch.histc(target, bins=K, min=0, max=K-1)\n",
        "    area_union = area_output + area_target - area_intersection\n",
        "    return area_intersection, area_union, area_target"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "t87VEMV2NJlx"
      },
      "outputs": [],
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = Model(n_classes=6).to(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "8fXOfQ4RvC2J"
      },
      "outputs": [],
      "source": [
        "# img = os.listdir('/content/drive/MyDrive/Dataset/zoomx20/Image2')\n",
        "# mask = os.listdir('/content/drive/MyDrive/Dataset/zoomx20/Mask2')\n",
        "# a = []\n",
        "\n",
        "# for i in img:\n",
        "#   t = i.replace('.jpg', '_classimg_nonconvex.png')\n",
        "#   if t not in mask:\n",
        "#     a.append(i)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GMTdfOqVN9Ik",
        "outputId": "459c50b9-daf2-4594-dda2-dff4ec4e851b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "num_workers = 2\n"
          ]
        }
      ],
      "source": [
        "#load data\n",
        "batch_size = 7\n",
        "n_workers = os.cpu_count()\n",
        "print(\"num_workers =\", n_workers)\n",
        "train_dataset = get_dataset(imgdir='/content/drive/MyDrive/Dataset/zoomx20/Image2',\n",
        "                        maskdir='/content/drive/MyDrive/Dataset/zoomx20/Mask2',\n",
        "                        train=True, val=False, test=False, transform=get_transform(train=False))\n",
        "\n",
        "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "#optimizer\n",
        "base_lr = 1e-3\n",
        "n_eps = 21\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=base_lr, momentum=0.9, weight_decay=1e-4)\n",
        "lr_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lambda x: (1 - x / (len(trainloader) * n_eps)) ** 0.9)\n",
        "\n",
        "#meter\n",
        "train_loss_meter = AverageMeter()\n",
        "intersection_meter = AverageMeter()\n",
        "union_meter = AverageMeter()\n",
        "target_meter = AverageMeter()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07k--X9Evuea",
        "outputId": "840b5d64-4b33-4569-e713-11fee33f3dfd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model.load_state_dict(torch.load('/content/drive/MyDrive/Model/Savemodel/Model_ep9.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "51x2IuqfOOFb",
        "outputId": "3b8a6db8-f972-42d1-b7f9-ad494c9cba06"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 190/429 [15:04<17:51,  4.49s/it]"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "#training script\n",
        "for ep in range(11, n_eps):\n",
        "    train_loss_meter.reset()\n",
        "    intersection_meter.reset()\n",
        "    union_meter.reset()\n",
        "    target_meter.reset()\n",
        "    model.train()\n",
        "    max_iter = n_eps * len(trainloader)\n",
        "    for batch_id, (x, y) in enumerate(tqdm(trainloader), start=1):\n",
        "        #qua trinh hoc mo hinh theo batch\n",
        "        optimizer.zero_grad()\n",
        "        n = x.shape[0]\n",
        "        x = x.to(device).float()\n",
        "        y = y.to(device).long()\n",
        "        y_hat_mask, main_loss, aux_loss = model(x, y)\n",
        "        loss = main_loss + aux_loss*0.4\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        #save metrics\n",
        "        with torch.no_grad():\n",
        "            train_loss_meter.update(loss.item())\n",
        "            intersection, union, target = intersectionAndUnionGPU(y_hat_mask.float(), y.float(), 6)\n",
        "            intersection_meter.update(intersection)\n",
        "            union_meter.update(union)\n",
        "            target_meter.update(target)\n",
        "    #compute iou, dice\n",
        "    with torch.no_grad():\n",
        "        accuracy = sum(intersection_meter.val) / (sum(target_meter.val) + 1e-10)\n",
        "        iou_class = intersection_meter.sum / (union_meter.sum + 1e-10) #vector 6D\n",
        "        dice_class = (2 * intersection_meter.sum) / (intersection_meter.sum + union_meter.sum + 1e-10) #vector 6D\n",
        "        mIoU = torch.mean(iou_class) #mean vector 6D\n",
        "        mDice = torch.mean(dice_class) #mean vector 6D\n",
        "\n",
        "    print(f\"\\nEP {ep}, train loss = {train_loss_meter.avg}, mIoU = {round(mIoU.item(), 4)}, mDice = {round(mDice.item(), 4)}, Accurancy = {round(accuracy.item(), 4)}\")\n",
        "    if ep % 5==0:\n",
        "      torch.save(model.state_dict(), f'/content/drive/MyDrive/Model/Savemodel/Model_ep{ep}.pth')\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "print('Training time {}'.format(total_time_str))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CeW1j_6vOaAJ"
      },
      "source": [
        "**<center>RUN TEST MODEL ON VALIDATION DATASET</center>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cAqtXFs_OmtU"
      },
      "outputs": [],
      "source": [
        "Val_train = get_dataset(imgdir='/content/drive/MyDrive/MyProject/Val/val_dataset',\n",
        "                        maskdir='/content/drive/MyDrive/MyProject/Val/val_mask',\n",
        "                        train=False,\n",
        "                        val=True,\n",
        "                        test=False,\n",
        "                        transform=get_transform(train=False))\n",
        "Valloader = torch.utils.data.DataLoader(Val_train, batch_size=batch_size,\n",
        "                                          shuffle=False, num_workers=n_workers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s21m8iLNOXJN"
      },
      "outputs": [],
      "source": [
        "model.eval()\n",
        "test_intersection_meter = AverageMeter()\n",
        "test_union_meter = AverageMeter()\n",
        "test_target_meter = AverageMeter()\n",
        "with torch.no_grad():\n",
        "    for batch_id, (x, y) in enumerate(tqdm(Valloader), start=1):\n",
        "        n = x.shape[0]\n",
        "        x = x.to(device).float()\n",
        "        y = y.to(device).long()\n",
        "        y_hat = model(x)\n",
        "        y_hat = y_hat.squeeze(1)\n",
        "        y_hat_mask = y_hat.argmax(dim=1)\n",
        "\n",
        "        intersection, union, target = intersectionAndUnionGPU(y_hat_mask, y, 6)\n",
        "        test_intersection_meter.update(intersection)\n",
        "        test_union_meter.update(union)\n",
        "        test_target_meter.update(target)\n",
        "\n",
        "    accuracy = sum(test_intersection_meter.val) / (sum(test_target_meter.val) + 1e-10)\n",
        "    iou_class = test_intersection_meter.sum / (test_union_meter.sum + 1e-10)\n",
        "    dice_class = 2*test_intersection_meter.sum / (test_intersection_meter.sum + test_union_meter.sum + 1e-10)\n",
        "    mIoU = torch.mean(iou_class)\n",
        "    mDice = torch.mean(dice_class)\n",
        "\n",
        "print(f\"\\nTEST: mIoU = {round(mIoU.item(), 4)}, mDice = {round(mDice.item(), 4)}, Accurancy = {round(accuracy.item(), 4)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pXaXFOFaOyuJ"
      },
      "source": [
        "**<center>SHOW PREDICT IMAGE</center>**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1b7c2plzO512"
      },
      "outputs": [],
      "source": [
        "#predict\n",
        "test_dataset = get_dataset(imgdir='/content/drive/MyDrive/MyProject/Val/slide002_core037/img',\n",
        "                        maskdir='/content/drive/MyDrive/MyProject/Val/slide002_core037/mask',\n",
        "                        train=False,\n",
        "                        val=True,\n",
        "                        test=False,\n",
        "                        transform=get_transform(train=False))\n",
        "id = np.random.randint(16)\n",
        "with torch.no_grad():\n",
        "    model.eval()\n",
        "    test_intersection_meter = AverageMeter()\n",
        "    test_union_meter = AverageMeter()\n",
        "    test_target_meter = AverageMeter()\n",
        "\n",
        "    x, y = test_dataset.__getitem__(id)\n",
        "    xs = x.unsqueeze(0).to(device).float()\n",
        "    y = y.to(device).long()\n",
        "    y_hat = model(xs).argmax(dim=1).squeeze()\n",
        "\n",
        "    intersection, union, target = intersectionAndUnionGPU(y_hat, y, 6)\n",
        "    test_intersection_meter.update(intersection)\n",
        "    test_union_meter.update(union)\n",
        "    test_target_meter.update(target)\n",
        "\n",
        "    accuracy = sum(test_intersection_meter.val) / (sum(test_target_meter.val) + 1e-10)\n",
        "    iou_class = test_intersection_meter.sum / (test_union_meter.sum + 1e-10)\n",
        "    dice_class = 2*test_intersection_meter.sum / (test_intersection_meter.sum + test_union_meter.sum + 1e-10)\n",
        "    mIoU = torch.mean(iou_class)\n",
        "    mDice = torch.mean(dice_class)\n",
        "\n",
        "    print(f\"\\nTEST: mIoU = {round(mIoU.item(), 4)}, mDice = {round(mDice.item(), 4)},\\\n",
        "     Accurancy = {round(accuracy.item(), 4)}\")\n",
        "    y_hat = y_hat.cpu().numpy()\n",
        "\n",
        "    colors =[\"gray\", \"green\", \"blue\", \"blue\", \"gold\", \"red\"]\n",
        "    fig, axes  = plt.subplots(1, 3, figsize=(10, 6))\n",
        "    x = x.cpu().numpy()\n",
        "    y = y.cpu().numpy()\n",
        "    axes[0].imshow(Image.fromarray((x[0] * 255).astype(np.uint8)))\n",
        "    axes[1].imshow(y, cmap=matplotlib.colors.ListedColormap(colors), interpolation=\"none\", vmin=0, vmax=5)\n",
        "    axes[2].imshow(y_hat, cmap=matplotlib.colors.ListedColormap(colors), interpolation=\"none\", vmin=0, vmax=5)\n",
        "    plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
