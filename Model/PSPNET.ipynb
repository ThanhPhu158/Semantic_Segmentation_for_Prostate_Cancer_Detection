{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dpjKqoH7lUPH",
        "outputId": "d1105dc1-c9c4-4e77-818f-9b7ad9c0164b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "-7h9L8LwzqP0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import cv2\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import albumentations as A\n",
        "from albumentations.pytorch import ToTensorV2 # np.array -> torch.tensor\n",
        "import os\n",
        "import os.path as osp\n",
        "from PIL import Image\n",
        "from torchvision import transforms as T\n",
        "from torchvision.transforms import functional as Ft\n",
        "\n",
        "from tqdm import tqdm\n",
        "from glob import glob\n",
        "import datetime\n",
        "import time\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import f1_score\n",
        "import matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "mHQPQ_UezqP3"
      },
      "outputs": [],
      "source": [
        "# VGG Cell\n",
        "class conv(nn.Module):\n",
        "    def __init__(self, in_ch, out_ch, num, stride=1, padding=1, dilation=1):\n",
        "        super(conv, self).__init__()\n",
        "        first_conv = nn.Sequential(nn.Conv2d(in_ch, out_ch, 3, stride=stride, padding=padding, dilation=dilation, bias=False),\n",
        "                                    nn.BatchNorm2d(out_ch),\n",
        "                                    nn.ReLU(inplace=True),\n",
        "                                    nn.Dropout(p=0.15)\n",
        "                                )\n",
        "        self.conv = nn.ModuleList([])\n",
        "        self.conv.append(first_conv)\n",
        "        for _ in range(num-1):\n",
        "            self.conv.append(\n",
        "                nn.Sequential(nn.Conv2d(out_ch, out_ch, 3, stride=stride, padding=padding, dilation=dilation, bias=False),\n",
        "                            nn.BatchNorm2d(out_ch),\n",
        "                            nn.ReLU(inplace=True),\n",
        "                            nn.Dropout(p=0.15)\n",
        "                        )\n",
        "            )\n",
        "    def forward(self, x):\n",
        "        for i in range(len(self.conv)):\n",
        "            x = self.conv[i](x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "3doKKY5TzqP4"
      },
      "outputs": [],
      "source": [
        "class FCN8s(nn.Module):\n",
        "    def __init__(self, n_classes=6):\n",
        "        super().__init__()\n",
        "        self.n_class = n_classes\n",
        "        # VGG BackBone\n",
        "        self.conv1 = conv(3, 64, 2)\n",
        "        # [N,3,224,224]->[N,64,256,256]\n",
        "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        # [N,64,224,224]->[N,64,128,128]\n",
        "\n",
        "        self.conv2 = conv(64, 128, 2)\n",
        "        # [N,64,112,112]->[N,128,128,128]\n",
        "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        # [N,128,112,112]->[N,128,64,64]\n",
        "\n",
        "        self.conv3 = conv(128, 256, 3)\n",
        "        # [N,128,56,56]->[N,256,64,64]\n",
        "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        # [N,256,56,56]->[N,256,32,32]\n",
        "\n",
        "        self.conv4 = conv(256, 512, 3, stride=1, padding=2, dilation=2)\n",
        "        # [N,256,28,28]->[N,512,32,32]\n",
        "        self.pool4 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        # [N,512,28,28]->[N,512,16,16]\n",
        "\n",
        "        self.conv5 = conv(512, 512, 3, stride=1, padding=2, dilation=2)\n",
        "        self.pool5 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        # [N,512,14,14]->[N,512,8,8]\n",
        "\n",
        "        self.conv6 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=512, out_channels=4096,\n",
        "                      kernel_size=7, padding=3),\n",
        "            nn.BatchNorm2d(4096),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.conv7 = nn.Sequential(\n",
        "            nn.Conv2d(in_channels=4096, out_channels=4096,\n",
        "                      kernel_size=1),\n",
        "            nn.BatchNorm2d(4096),\n",
        "            nn.ReLU(),\n",
        "        )\n",
        "        self.score_fr = nn.Conv2d(in_channels=4096, out_channels=128,\n",
        "                                   kernel_size=1)\n",
        "        self.upscore2 = nn.ConvTranspose2d(in_channels=128, out_channels=128,\n",
        "                                           kernel_size=4, stride=2, padding=1)\n",
        "\n",
        "        self.score_pool4 = nn.Conv2d(in_channels=512, out_channels=128,\n",
        "                                     kernel_size=1)\n",
        "\n",
        "        self.upscore_pool4 = nn.ConvTranspose2d(in_channels=128, out_channels=128,\n",
        "                                                kernel_size=4, stride=2, padding=1)\n",
        "        self.score_pool3 = nn.Conv2d(in_channels=256, out_channels=128,\n",
        "                                     kernel_size=1)\n",
        "\n",
        "        self.upscore8 = nn.ConvTranspose2d(in_channels=128, out_channels=128,\n",
        "                                           kernel_size=16, stride=8, padding=4)\n",
        "        self.finalconv = nn.Sequential(nn.Conv2d(128, 128, kernel_size=1, padding=0))\n",
        "    def forward(self, x):\n",
        "        x1 = self.conv1(x)\n",
        "        p1 = self.pool1(x1)\n",
        "        x2 = self.conv2(p1)\n",
        "        p2 = self.pool2(x2)\n",
        "        x3 = self.conv3(p2)\n",
        "        p3 = self.pool3(x3)\n",
        "        x4 = self.conv4(p3)\n",
        "        p4 = self.pool4(x4)\n",
        "        x5 = self.conv5(p4)\n",
        "        p5 = self.pool5(x5)\n",
        "\n",
        "        x6 = self.conv6(p5)\n",
        "        x7 = self.conv7(x6)\n",
        "\n",
        "        sf = self.score_fr(x7)\n",
        "        u2 = self.upscore2(sf)\n",
        "\n",
        "        s4 = self.score_pool4(p4)\n",
        "        f4 = torch.add(s4, u2)\n",
        "        u4 = self.upscore_pool4(f4)\n",
        "\n",
        "        s3 = self.score_pool3(p3)\n",
        "        f3 = torch.add(s3, u4)\n",
        "        u3 = self.upscore8(f3)\n",
        "\n",
        "        out = self.finalconv(u3)\n",
        "        return out, p3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "D9W_OMutzqP5"
      },
      "outputs": [],
      "source": [
        "# model = FCN8s()\n",
        "# x = torch.rand(4, 3, 256, 256)\n",
        "# y, aux = model(x)\n",
        "# print(aux.size())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "gmFGUFh4zqP5"
      },
      "outputs": [],
      "source": [
        "def conv3x3(in_ch, out_ch, stride=1):\n",
        "    \"\"\"3x3 convolution with padding\"\"\"\n",
        "    return nn.Conv2d(in_ch, out_ch, kernel_size=3, stride=stride,\n",
        "                     padding=1, bias=False)\n",
        "\n",
        "\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "    def __init__(self, in_ch, out_ch, stride=1, downsample=None):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = conv3x3(in_ch, out_ch, stride)\n",
        "        self.bn1 = nn.BatchNorm2d(out_ch)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.conv2 = conv3x3(out_ch, out_ch)\n",
        "        self.bn2 = nn.BatchNorm2d(out_ch)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "    def __init__(self, in_ch, out_ch, stride=1, downsample=None):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_ch, out_ch, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(out_ch)\n",
        "        self.conv2 = nn.Conv2d(out_ch, out_ch, kernel_size=3, stride=stride,\n",
        "                               padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(out_ch)\n",
        "        self.conv3 = nn.Conv2d(out_ch, out_ch * self.expansion, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(out_ch * self.expansion)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.downsample = downsample\n",
        "        self.stride = stride\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "\n",
        "        out = self.conv1(x)\n",
        "        out = self.bn1(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv2(out)\n",
        "        out = self.bn2(out)\n",
        "        out = self.relu(out)\n",
        "\n",
        "        out = self.conv3(out)\n",
        "        out = self.bn3(out)\n",
        "\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "\n",
        "        out += residual\n",
        "        out = self.relu(out)\n",
        "\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, layers, num_classes=1000, deep_base=True):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.deep_base = deep_base\n",
        "        if not self.deep_base:\n",
        "            self.in_ch = 64\n",
        "            self.conv1 = nn.Conv2d(3, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
        "            self.bn1 = nn.BatchNorm2d(64)\n",
        "        else:\n",
        "            self.in_ch = 128\n",
        "            self.conv1 = conv3x3(3, 64, stride=2)\n",
        "            self.bn1 = nn.BatchNorm2d(64)\n",
        "            self.conv2 = conv3x3(64, 64)\n",
        "            self.bn2 = nn.BatchNorm2d(64)\n",
        "            self.conv3 = conv3x3(64, 128)\n",
        "            self.bn3 = nn.BatchNorm2d(128)\n",
        "        self.relu = nn.ReLU(inplace=True)\n",
        "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
        "        self.layer1 = self._make_layer(block, 64, layers[0])\n",
        "        self.layer2 = self._make_layer(block, 128, layers[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, layers[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, layers[3], stride=2)\n",
        "        self.avgpool = nn.AvgPool2d(7, stride=1)\n",
        "        self.fc = nn.Linear(512 * block.expansion, num_classes)\n",
        "\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "\n",
        "    def _make_layer(self, block, out_ch, blocks, stride=1):\n",
        "        downsample = None\n",
        "        if stride != 1 or self.in_ch != out_ch * block.expansion:\n",
        "            downsample = nn.Sequential(\n",
        "                nn.Conv2d(self.in_ch, out_ch * block.expansion,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(out_ch * block.expansion),\n",
        "            )\n",
        "\n",
        "        layers = []\n",
        "        layers.append(block(self.in_ch, out_ch, stride, downsample))\n",
        "        self.in_ch = out_ch * block.expansion\n",
        "        for i in range(1, blocks):\n",
        "            layers.append(block(self.in_ch, out_ch))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.bn1(self.conv1(x)))\n",
        "        if self.deep_base:\n",
        "            x = self.relu(self.bn2(self.conv2(x)))\n",
        "            x = self.relu(self.bn3(self.conv3(x)))\n",
        "        x = self.maxpool(x)\n",
        "\n",
        "        x = self.layer1(x)\n",
        "        x = self.layer2(x)\n",
        "        x = self.layer3(x)\n",
        "        x = self.layer4(x)\n",
        "\n",
        "        x = self.avgpool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.fc(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "\n",
        "def resnet152(pretrained=True, **kwargs):\n",
        "    \"\"\"Constructs a ResNet-152 model.\n",
        "    Args:\n",
        "        pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "    \"\"\"\n",
        "    model = ResNet(Bottleneck, [3, 8, 36, 3], **kwargs)\n",
        "    if pretrained:\n",
        "        # model.load_state_dict(model_zoo.load_url(model_urls['resnet152']))\n",
        "        model_path = '/content/drive/MyDrive/Dataset/resnet152_v2.pth'\n",
        "        model.load_state_dict(torch.load(model_path), strict=False)\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "DpiwulhzzqP6"
      },
      "outputs": [],
      "source": [
        "class PPM(nn.Module):\n",
        "    def __init__(self, in_dim, reduction_dim, bins):\n",
        "        super(PPM, self).__init__()\n",
        "        self.features = []\n",
        "        for bin in bins:\n",
        "            self.features.append(nn.Sequential(\n",
        "                nn.AdaptiveAvgPool2d(bin),\n",
        "                nn.Conv2d(in_dim, reduction_dim, kernel_size=1, bias=False),\n",
        "                nn.BatchNorm2d(reduction_dim),\n",
        "                nn.ReLU(inplace=True)\n",
        "            ))\n",
        "        self.features = nn.ModuleList(self.features)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_size = x.size()\n",
        "        out = [x]\n",
        "        for f in self.features:\n",
        "            out.append(F.interpolate(f(x), x_size[2:], mode='bilinear', align_corners=True))\n",
        "        return torch.cat(out, 1)\n",
        "\n",
        "class PSPNet(nn.Module):\n",
        "    def __init__(self, bins=(1, 2, 3, 6), dropout=0.15, n_classes=6, zoom_factor=8):\n",
        "        super(PSPNet, self).__init__()\n",
        "        assert 2048 % len(bins) == 0\n",
        "        assert n_classes > 1\n",
        "        assert zoom_factor in [1, 2, 4, 8]\n",
        "        self.zoom_factor = zoom_factor\n",
        "\n",
        "        resnet = resnet152(pretrained=True)\n",
        "        self.layer0_0 = nn.Sequential(resnet.conv1, resnet.bn1, resnet.relu)\n",
        "        self.layer0_1 = nn.Sequential(resnet.conv2, resnet.bn2, resnet.relu)\n",
        "        self.layer0_2 = nn.Sequential(resnet.conv3, resnet.bn3, resnet.relu,\n",
        "                                        resnet.maxpool)\n",
        "        self.layer1, self.layer2, self.layer3, self.layer4 = resnet.layer1, resnet.layer2, resnet.layer3, resnet.layer4\n",
        "\n",
        "        for n, m in self.layer4.named_modules():\n",
        "            if 'conv2' in n:\n",
        "                m.dilation, m.padding, m.stride = (2, 2), (2, 2), (1, 1)\n",
        "            elif 'downsample.0' in n:\n",
        "                m.stride = (1, 1)\n",
        "\n",
        "        fea_dim = 2048\n",
        "        self.ppm = PPM(fea_dim, int(fea_dim/len(bins)), bins)\n",
        "        fea_dim *= 2\n",
        "        self.cls = nn.Sequential(\n",
        "            nn.Conv2d(fea_dim, 512, kernel_size=3, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(512),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout2d(p=dropout),\n",
        "            nn.Conv2d(512, 128, kernel_size=1)\n",
        "        )\n",
        "        self.finalconv = nn.Conv2d(128, 128, kernel_size=1, padding=0, bias=False)\n",
        "\n",
        "    def forward(self, x):\n",
        "        _, _, h, w = x.size()\n",
        "        x0_0 = self.layer0_0(x)\n",
        "        x0_1 = self.layer0_1(x0_0)\n",
        "        x0_2 = self.layer0_2(x0_1)\n",
        "        x1 = self.layer1(x0_2)\n",
        "        x2 = self.layer2(x1)\n",
        "        x3 = self.layer3(x2)\n",
        "        x4 = self.layer4(x3)\n",
        "        x_ppm = self.ppm(x4)\n",
        "        x_cls = self.cls(x_ppm)\n",
        "        x = F.interpolate(x_cls, size=(h, w), mode='bilinear', align_corners=True)\n",
        "        x = self.finalconv(x)\n",
        "        return x, x2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FocalLoss(nn.Module):\n",
        "    def __init__(self, gamma=0, alpha=None, size_average=True):\n",
        "        super(FocalLoss, self).__init__()\n",
        "        self.gamma = gamma\n",
        "        self.alpha = alpha\n",
        "        if isinstance(alpha,(float,int)):\n",
        "          self.alpha = torch.Tensor([alpha,1-alpha])\n",
        "        if isinstance(alpha,list):\n",
        "          self.alpha = torch.Tensor(alpha)\n",
        "        self.size_average = size_average\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        if input.dim() > 2:\n",
        "            input = input.view(input.size(0),input.size(1),-1)  # N,C,H,W => N,C,H*W\n",
        "            input = input.transpose(1,2)    # N,C,H*W => N,H*W,C\n",
        "            input = input.contiguous().view(-1,input.size(2))   # N,H*W,C => N*H*W,C\n",
        "        target = target.view(-1,1)\n",
        "\n",
        "        logpt = F.log_softmax(input, dim=1)\n",
        "        logpt = logpt.gather(1,target)\n",
        "        logpt = logpt.view(-1)\n",
        "        pt = Variable(logpt.data.exp())\n",
        "\n",
        "        if self.alpha is not None:\n",
        "            if self.alpha.type()!=input.data.type():\n",
        "                self.alpha = self.alpha.type_as(input.data)\n",
        "            at = self.alpha.gather(0,target.data.view(-1))\n",
        "            logpt = logpt * Variable(at)\n",
        "\n",
        "        loss = -1 * (1-pt)**self.gamma * logpt\n",
        "        if self.size_average:\n",
        "          return loss.mean()\n",
        "        else:\n",
        "          return loss.sum()"
      ],
      "metadata": {
        "id": "VeuhBSajo1tR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "vdGKCpFEzqP6"
      },
      "outputs": [],
      "source": [
        "class MainModel(nn.Module):\n",
        "    def __init__(self, n_classes=6, lossFunc=FocalLoss()):\n",
        "        super(MainModel, self).__init__()\n",
        "        self.criterion= lossFunc\n",
        "        if self.training:\n",
        "            self.aux = nn.Sequential(\n",
        "                nn.Conv2d(768, 256, kernel_size=3, padding=1, bias=False),\n",
        "                nn.BatchNorm2d(256),\n",
        "                nn.ReLU(inplace=True),\n",
        "                nn.Dropout2d(p=0.15),\n",
        "                nn.Conv2d(256, n_classes, kernel_size=1)\n",
        "            )\n",
        "\n",
        "        self.pspnet = PSPNet()\n",
        "        self.fcn8s = FCN8s()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, dilation=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, 256, kernel_size=3, stride=1, dilation=1, padding=1, bias=False),\n",
        "            nn.BatchNorm2d(256),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(256, n_classes, kernel_size=1, stride=1, dilation=1, padding=0, bias=False),\n",
        "        )\n",
        "\n",
        "    def forward(self, x, y=None):\n",
        "        _, _, h, w = x.size()\n",
        "        psp, psp_aux = self.pspnet(x)\n",
        "        fcn, fcn_aux = self.fcn8s(x)\n",
        "        x_out = torch.cat([psp, fcn], dim=1)\n",
        "        x_out = self.conv(x_out)\n",
        "\n",
        "        aux_in = torch.cat([psp_aux, fcn_aux], dim=1)\n",
        "        if self.training:\n",
        "            aux = self.aux(aux_in)\n",
        "            aux = F.interpolate(aux, size=(h, w), mode='bilinear', align_corners=True)\n",
        "            aux_loss = self.criterion(aux, y)\n",
        "            main_loss = self.criterion(x_out, y)\n",
        "            return x_out.max(1)[1], main_loss, aux_loss\n",
        "        else:\n",
        "            return x_out\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Gleason(Dataset):\n",
        "    def __init__(self, imgdir, maskdir=None, train=True, val=False,\n",
        "                 test=False, transform=None, target_transform=None):\n",
        "        super(Gleason, self).__init__()\n",
        "        self.imgdir = imgdir\n",
        "        self.maskdir = maskdir\n",
        "        self.imglist = os.listdir(imgdir)\n",
        "        if not test:\n",
        "            self.masklist = [item.replace('.jpg', '_classimg_nonconvex.png') for item in self.imglist]\n",
        "        else:\n",
        "            self.masklist = []\n",
        "\n",
        "        self.train = train\n",
        "        self.val = val\n",
        "        self.test = test\n",
        "        self.transform = transform\n",
        "        self.target_transform = target_transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.imglist)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        image = np.array(Image.open(f'{self.imgdir}/{self.imglist[idx]}'))\n",
        "        if self.test == True:\n",
        "            transformed = self.transform(image=image)\n",
        "            image = transformed[\"image\"]\n",
        "            return image\n",
        "        mask = np.array(Image.open(f'{self.maskdir}/{self.masklist[idx]}'))\n",
        "        if self.transform:\n",
        "            transformed = self.transform(image=image, mask=mask)\n",
        "            image = transformed[\"image\"]\n",
        "            mask = transformed[\"mask\"]\n",
        "        if self.target_transform:\n",
        "            mask = self.target_transform(mask)\n",
        "        return image, mask"
      ],
      "metadata": {
        "id": "4-UilovDmMC6"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_dataset(imgdir, maskdir=None, train=True, val=False, test=False,\n",
        "                transform=None, target_transform=None):\n",
        "    dataset = Gleason(imgdir=imgdir, maskdir=maskdir, train=train,\n",
        "                      val=val, test=test, transform=transform, target_transform=target_transform)\n",
        "    return dataset\n",
        "\n",
        "\n",
        "def get_transform(train):\n",
        "    if train:\n",
        "        return A.Compose([\n",
        "            A.Resize(width=256, height=256),\n",
        "            A.ShiftScaleRotate(shift_limit=0.2, scale_limit=0.2, rotate_limit=30, p=0.5),\n",
        "            A.PadIfNeeded(min_height=256, min_width=256),\n",
        "            A.RandomCrop(256, 256),\n",
        "            A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0),\n",
        "            ToTensorV2(),\n",
        "        ])\n",
        "    else:\n",
        "        return A.Compose([\n",
        "        A.Resize(width=256, height=256),\n",
        "        A.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225), max_pixel_value=255.0),\n",
        "        ToTensorV2(), # numpy.array -> torch.tensor (B, 3, H, W)\n",
        "        ])\n"
      ],
      "metadata": {
        "id": "x5XwZ_aLm0GO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class AverageMeter(object):\n",
        "    def __init__(self):\n",
        "        self.reset()\n",
        "\n",
        "    def reset(self):\n",
        "        self.val = 0\n",
        "        self.avg = 0\n",
        "        self.sum = 0\n",
        "        self.count = 0\n",
        "\n",
        "    def update(self, val, n=1):\n",
        "        self.val = val\n",
        "        self.sum += val * n\n",
        "        self.count += n\n",
        "        self.avg = self.sum / self.count"
      ],
      "metadata": {
        "id": "OFf86B1vm6le"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#metrics\n",
        "def intersectionAndUnionGPU(output, target, K, ignore_index=255):\n",
        "    # 'K' classes, output and target sizes are N or N * L or N * H * W, each value in range 0 to K - 1.\n",
        "    assert output.shape == target.shape\n",
        "    output = output.view(-1)\n",
        "    target = target.view(-1)\n",
        "    output[target == ignore_index] = ignore_index\n",
        "    intersection = output[output == target]\n",
        "    area_intersection = torch.histc(intersection, bins=K, min=0, max=K-1)\n",
        "    area_output = torch.histc(output, bins=K, min=0, max=K-1)\n",
        "    area_target = torch.histc(target, bins=K, min=0, max=K-1)\n",
        "    area_union = area_output + area_target - area_intersection\n",
        "    return area_intersection, area_union, area_target"
      ],
      "metadata": {
        "id": "Aa2_g3FFm7FP"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = MainModel().to(device)"
      ],
      "metadata": {
        "id": "gkc6WC-km9f5"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load data\n",
        "batch_size = 10\n",
        "n_workers = os.cpu_count()\n",
        "print(\"num_workers =\", n_workers)\n",
        "n_eps = 100\n",
        "#optimizer\n",
        "base_lr = 1e-3\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=base_lr, momentum=0.9, weight_decay=1e-4)\n",
        "#dataloader\n",
        "train_dataset = get_dataset(imgdir=f'/content/drive/MyDrive/Dataset/Image_x4/Image',\n",
        "                  maskdir=f'/content/drive/MyDrive/Dataset/Image_x4/Mask',\n",
        "                  train=True, val=False, test=False, transform=get_transform(train=False))\n",
        "trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "lr_scheduler = torch.optim.lr_scheduler.LambdaLR(optimizer, lambda x: (1 - x / (len(trainloader) * n_eps)) ** 0.9)\n",
        "max_iter = n_eps * len(trainloader)\n",
        "#meter\n",
        "train_loss_meter = AverageMeter()\n",
        "intersection_meter = AverageMeter()\n",
        "union_meter = AverageMeter()\n",
        "target_meter = AverageMeter()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oW5jhkGHnCDC",
        "outputId": "1451dc50-10df-40ee-98e1-bf7931d4aaa8"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "num_workers = 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "#training script\n",
        "for ep in range(0, n_eps):\n",
        "    train_loss_meter.reset()\n",
        "    intersection_meter.reset()\n",
        "    union_meter.reset()\n",
        "    target_meter.reset()\n",
        "    if ep > 15:\n",
        "      train_dataset = get_dataset(imgdir=f'/content/drive/MyDrive/Dataset/Image_x4/Image',\n",
        "                  maskdir=f'/content/drive/MyDrive/Dataset/Image_x4/Mask',\n",
        "                  train=True, val=False, test=False, transform=get_transform(train=True))\n",
        "      trainloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    model.train()\n",
        "    for batch_id, (x, y) in enumerate(tqdm(trainloader), start=1):\n",
        "        #qua trinh hoc mo hinh theo batch\n",
        "        optimizer.zero_grad()\n",
        "        n = x.shape[0]\n",
        "        x = x.to(device).float()\n",
        "        y = y.to(device).long()\n",
        "        y_hat_mask, main_loss, aux_loss = model(x, y)\n",
        "        loss = main_loss + aux_loss*0.4\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "        #save metrics\n",
        "        with torch.no_grad():\n",
        "            train_loss_meter.update(loss.item())\n",
        "            intersection, union, target = intersectionAndUnionGPU(y_hat_mask.float(), y.float(), 6)\n",
        "            intersection_meter.update(intersection)\n",
        "            union_meter.update(union)\n",
        "            target_meter.update(target)\n",
        "    #compute iou, dice\n",
        "    with torch.no_grad():\n",
        "        accuracy = sum(intersection_meter.val) / (sum(target_meter.val) + 1e-10)\n",
        "        iou_class = intersection_meter.sum / (union_meter.sum + 1e-10) #vector 6D\n",
        "        dice_class = (2 * intersection_meter.sum) / (intersection_meter.sum + union_meter.sum + 1e-10) #vector 6D\n",
        "        mIoU = torch.mean(iou_class) #mean vector 6D\n",
        "        mDice = torch.mean(dice_class) #mean vector 6D\n",
        "\n",
        "    print(f\"EP {ep}, train loss = {train_loss_meter.avg}, mIoU = {round(mIoU.item(), 4)}, mDice = {round(mDice.item(), 4)}, Accurancy = {round(accuracy.item(), 4)}\")\n",
        "    if ep % 10==0:\n",
        "      torch.save(model.state_dict(), f'/content/drive/MyDrive/Model/Savemodel/Model_ep{ep}.pth')\n",
        "\n",
        "total_time = time.time() - start_time\n",
        "total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n",
        "print('Training time {}'.format(total_time_str))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPUVmWOZnG1j",
        "outputId": "fd11ee74-38f9-4d82-f6fc-a2cc984a95bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 90%|█████████ | 687/762 [3:48:42<24:48, 19.85s/it]"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "orig_nbformat": 4,
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}